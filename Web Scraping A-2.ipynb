{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import selenium\n",
    "from selenium import webdriver\n",
    "import time\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "from selenium.webdriver.common.by import By"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Q1: Write a python program to scrape data for “Data Analyst” Job position in “Bangalore” location. You have to scrape the job-title, job-location, company_name, experience_required. You have to scrape first 10 jobs data.\n",
    "## Webpage https://www.naukri.com/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Job Title</th>\n",
       "      <th>Job Location</th>\n",
       "      <th>Company Name</th>\n",
       "      <th>Experience Required</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Data Analyst Analyzing</td>\n",
       "      <td>Bangalore/Bengaluru</td>\n",
       "      <td>Cistup Indian Institute of Science</td>\n",
       "      <td>2-5 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Senior Analyst-Data Visualization</td>\n",
       "      <td>Bangalore/Bengaluru</td>\n",
       "      <td>Accenture Solutions Pvt Ltd</td>\n",
       "      <td>5-8 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Market Unit - Data Business Analyst (11)</td>\n",
       "      <td>Bangalore/Bengaluru</td>\n",
       "      <td>Accenture Solutions Pvt Ltd</td>\n",
       "      <td>1-2 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Data Analyst</td>\n",
       "      <td>Bangalore/Bengaluru</td>\n",
       "      <td>Myntra Designs Pvt. Ltd.</td>\n",
       "      <td>3-6 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Analyst-Finance Data Maintenance</td>\n",
       "      <td>Bangalore/Bengaluru</td>\n",
       "      <td>Accenture Solutions Pvt Ltd</td>\n",
       "      <td>3-5 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Senior Analyst-Data Management</td>\n",
       "      <td>Bangalore/Bengaluru</td>\n",
       "      <td>Accenture Solutions Pvt Ltd</td>\n",
       "      <td>5-8 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Analyst-Data Management</td>\n",
       "      <td>Bangalore/Bengaluru</td>\n",
       "      <td>Accenture Solutions Pvt Ltd</td>\n",
       "      <td>3-5 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Senior Analyst-Data Management</td>\n",
       "      <td>Bangalore/Bengaluru</td>\n",
       "      <td>Accenture Solutions Pvt Ltd</td>\n",
       "      <td>5-8 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Senior Analyst-Data Visualization</td>\n",
       "      <td>Bangalore/Bengaluru</td>\n",
       "      <td>Accenture Solutions Pvt Ltd</td>\n",
       "      <td>5-8 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Senior Analyst-Finance Data Maintenance</td>\n",
       "      <td>Bangalore/Bengaluru</td>\n",
       "      <td>Accenture Solutions Pvt Ltd</td>\n",
       "      <td>5-8 Yrs</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                  Job Title         Job Location  \\\n",
       "0                    Data Analyst Analyzing  Bangalore/Bengaluru   \n",
       "1         Senior Analyst-Data Visualization  Bangalore/Bengaluru   \n",
       "2  Market Unit - Data Business Analyst (11)  Bangalore/Bengaluru   \n",
       "3                              Data Analyst  Bangalore/Bengaluru   \n",
       "4          Analyst-Finance Data Maintenance  Bangalore/Bengaluru   \n",
       "5            Senior Analyst-Data Management  Bangalore/Bengaluru   \n",
       "6                   Analyst-Data Management  Bangalore/Bengaluru   \n",
       "7            Senior Analyst-Data Management  Bangalore/Bengaluru   \n",
       "8         Senior Analyst-Data Visualization  Bangalore/Bengaluru   \n",
       "9   Senior Analyst-Finance Data Maintenance  Bangalore/Bengaluru   \n",
       "\n",
       "                         Company Name Experience Required  \n",
       "0  Cistup Indian Institute of Science             2-5 Yrs  \n",
       "1         Accenture Solutions Pvt Ltd             5-8 Yrs  \n",
       "2         Accenture Solutions Pvt Ltd             1-2 Yrs  \n",
       "3            Myntra Designs Pvt. Ltd.             3-6 Yrs  \n",
       "4         Accenture Solutions Pvt Ltd             3-5 Yrs  \n",
       "5         Accenture Solutions Pvt Ltd             5-8 Yrs  \n",
       "6         Accenture Solutions Pvt Ltd             3-5 Yrs  \n",
       "7         Accenture Solutions Pvt Ltd             5-8 Yrs  \n",
       "8         Accenture Solutions Pvt Ltd             5-8 Yrs  \n",
       "9         Accenture Solutions Pvt Ltd             5-8 Yrs  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Function Definition\n",
    "def data_analyst(url):\n",
    "    driver1=webdriver.Chrome(\"C://chromedriver.exe\")\n",
    "    driver1.get(url)\n",
    "    time.sleep(6)\n",
    "    \n",
    "    enter_job=driver1.find_element_by_id('qsb-keyword-sugg')\n",
    "    enter_job.send_keys('Data Analyst')\n",
    "    enter_loc=driver1.find_element_by_id('qsb-location-sugg')\n",
    "    enter_loc.send_keys('Bangalore')\n",
    "    search_butn=driver1.find_element_by_xpath(\"//div[@class='search-btn']/button\")\n",
    "    search_butn.click()\n",
    "    time.sleep(6)\n",
    "    \n",
    "#     Let's create empty lists to store necessary information \n",
    "    job_titles=[]\n",
    "    job_locs=[]\n",
    "    comp_names=[]\n",
    "    exp_req=[]\n",
    "    \n",
    "#     extracting job titles\n",
    "    for i in driver1.find_elements_by_xpath(\"//a[@class='title fw500 ellipsis']\"):\n",
    "        job_titles.append(i.text)\n",
    "#     extracting job locations\n",
    "    for i in driver1.find_elements_by_xpath(\"//li[@class='fleft grey-text br2 placeHolderLi location']/span\"):\n",
    "        job_locs.append(i.text)\n",
    "#     extracting companies names\n",
    "    for i in driver1.find_elements_by_xpath(\"//a[@class='subTitle ellipsis fleft']\"):\n",
    "        comp_names.append(i.text)\n",
    "#     extracting experience required\n",
    "    for i in driver1.find_elements_by_xpath(\"//li[@class='fleft grey-text br2 placeHolderLi experience']/span\"):\n",
    "        exp_req.append(i.text)\n",
    "    \n",
    "    Q1_DF=pd.DataFrame({})\n",
    "    Q1_DF['Job Title']=job_titles[:10]\n",
    "    Q1_DF['Job Location']=job_locs[:10]\n",
    "    Q1_DF['Company Name']=comp_names[:10]\n",
    "    Q1_DF['Experience Required']=exp_req[:10]\n",
    "    \n",
    "    driver1.close()\n",
    "    \n",
    "    return Q1_DF\n",
    "\n",
    "\n",
    "# Calling Function\n",
    "data_analyst('https://www.naukri.com/')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Q2: Write a python program to scrape data for “Data Scientist” Job position in “Bangalore” location. You have to scrape the job-title, job-location, company_name, full job-description. You have to scrape first 10 jobs data.\n",
    "## Webpage https://www.naukri.com/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Job Title</th>\n",
       "      <th>Job Location</th>\n",
       "      <th>Company Name</th>\n",
       "      <th>Job Description</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>Bangalore/Bengaluru</td>\n",
       "      <td>CronJ IT Technologies Private Limited</td>\n",
       "      <td>Responsibilities and DutiesCreate innovative s...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Opportunity For Data Scientist Internship - Be...</td>\n",
       "      <td>Bangalore/Bengaluru</td>\n",
       "      <td>Corner Stone Solutions</td>\n",
       "      <td>Location - Bangalore / BengaluruDuration- 6 Mo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Data Scientist/ Analyst</td>\n",
       "      <td>Bangalore/Bengaluru</td>\n",
       "      <td>Becton Dickinson India Pvt. Ltd</td>\n",
       "      <td>Roles and Responsibilitiesob Description Summa...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Data Scientist - Machine Learning</td>\n",
       "      <td>Bangalore/Bengaluru</td>\n",
       "      <td>AugmatrixGo</td>\n",
       "      <td>Roles and Responsibilities- Selecting features...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Data Scientist || Data Analyst || Data science</td>\n",
       "      <td>Navi Mumbai, Bangalore/Bengaluru</td>\n",
       "      <td>Inspiration Manpower Consultancy Pvt. Ltd.</td>\n",
       "      <td>Job descriptionJob Summary and Key Responsibil...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>DBCG IND - GAMMA Senior Data Scientist</td>\n",
       "      <td>Mumbai, New Delhi, Chennai, Bangalore/Bengaluru</td>\n",
       "      <td>Boston Consulting Group</td>\n",
       "      <td>What Youll DoWe re looking for a passionat...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Data Scientist/Senior Data Scientist</td>\n",
       "      <td>Hyderabad/Secunderabad, Pune, Chennai, Bangalo...</td>\n",
       "      <td>GANIT BUSINESS SOLUTIONS PRIVATE LIMITED</td>\n",
       "      <td>About Ganit IncFounded by senior industry expe...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Senior Data Scientist | CES IT LTD | CMMI Level 5</td>\n",
       "      <td>Kolkata, Mumbai, Hyderabad/Secunderabad, Pune,...</td>\n",
       "      <td>CES Ltd.</td>\n",
       "      <td>Roles and ResponsibilitiesMust have strong Pyt...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Global Medical Data Scientist</td>\n",
       "      <td>Bangalore/Bengaluru</td>\n",
       "      <td>GlaxoSmithKline Pharmaceuticals Limited</td>\n",
       "      <td>This is an ideal role for an experienced candi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Associate Data Scientist - CRM &amp; Loyalty</td>\n",
       "      <td>Bangalore/Bengaluru</td>\n",
       "      <td>Shell India Markets Private Limited</td>\n",
       "      <td>The RoleGeneral Position DefinitionThis role w...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                           Job Title  \\\n",
       "0                                     Data Scientist   \n",
       "1  Opportunity For Data Scientist Internship - Be...   \n",
       "2                            Data Scientist/ Analyst   \n",
       "3                  Data Scientist - Machine Learning   \n",
       "4     Data Scientist || Data Analyst || Data science   \n",
       "5             DBCG IND - GAMMA Senior Data Scientist   \n",
       "6               Data Scientist/Senior Data Scientist   \n",
       "7  Senior Data Scientist | CES IT LTD | CMMI Level 5   \n",
       "8                      Global Medical Data Scientist   \n",
       "9           Associate Data Scientist - CRM & Loyalty   \n",
       "\n",
       "                                        Job Location  \\\n",
       "0                                Bangalore/Bengaluru   \n",
       "1                                Bangalore/Bengaluru   \n",
       "2                                Bangalore/Bengaluru   \n",
       "3                                Bangalore/Bengaluru   \n",
       "4                   Navi Mumbai, Bangalore/Bengaluru   \n",
       "5    Mumbai, New Delhi, Chennai, Bangalore/Bengaluru   \n",
       "6  Hyderabad/Secunderabad, Pune, Chennai, Bangalo...   \n",
       "7  Kolkata, Mumbai, Hyderabad/Secunderabad, Pune,...   \n",
       "8                                Bangalore/Bengaluru   \n",
       "9                                Bangalore/Bengaluru   \n",
       "\n",
       "                                 Company Name  \\\n",
       "0       CronJ IT Technologies Private Limited   \n",
       "1                      Corner Stone Solutions   \n",
       "2             Becton Dickinson India Pvt. Ltd   \n",
       "3                                 AugmatrixGo   \n",
       "4  Inspiration Manpower Consultancy Pvt. Ltd.   \n",
       "5                     Boston Consulting Group   \n",
       "6    GANIT BUSINESS SOLUTIONS PRIVATE LIMITED   \n",
       "7                                    CES Ltd.   \n",
       "8     GlaxoSmithKline Pharmaceuticals Limited   \n",
       "9         Shell India Markets Private Limited   \n",
       "\n",
       "                                     Job Description  \n",
       "0  Responsibilities and DutiesCreate innovative s...  \n",
       "1  Location - Bangalore / BengaluruDuration- 6 Mo...  \n",
       "2  Roles and Responsibilitiesob Description Summa...  \n",
       "3  Roles and Responsibilities- Selecting features...  \n",
       "4  Job descriptionJob Summary and Key Responsibil...  \n",
       "5      What Youll DoWe re looking for a passionat...  \n",
       "6  About Ganit IncFounded by senior industry expe...  \n",
       "7  Roles and ResponsibilitiesMust have strong Pyt...  \n",
       "8  This is an ideal role for an experienced candi...  \n",
       "9  The RoleGeneral Position DefinitionThis role w...  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Function Definition\n",
    "def data_scie1(url):\n",
    "    driver2=webdriver.Chrome(\"C://chromedriver.exe\")\n",
    "    driver2.get(url)\n",
    "    time.sleep(6)\n",
    "    \n",
    "    enter_job=driver2.find_element_by_id('qsb-keyword-sugg')\n",
    "    enter_job.send_keys('Data Scientist')\n",
    "    enter_loc=driver2.find_element_by_id('qsb-location-sugg')\n",
    "    enter_loc.send_keys('Bangalore')\n",
    "    search_butn=driver2.find_element_by_xpath(\"//div[@class='search-btn']/button\")\n",
    "    search_butn.click()\n",
    "    time.sleep(6)\n",
    "    \n",
    "#     Let's create empty lists to store necessary information \n",
    "    job_titles=[]\n",
    "    job_locs=[]\n",
    "    comp_names=[]\n",
    "    jobs_desc=[]\n",
    "#     creating one empty list, to store jobs href\n",
    "    jobs_href=[]\n",
    "    \n",
    "#     extracting job titles\n",
    "    for i in driver2.find_elements_by_xpath(\"//a[@class='title fw500 ellipsis']\"):\n",
    "        job_titles.append(i.text)\n",
    "#     extracting job locations\n",
    "    for i in driver2.find_elements_by_xpath(\"//li[@class='fleft grey-text br2 placeHolderLi location']/span\"):\n",
    "        job_locs.append(i.text)\n",
    "#     extracting companies names\n",
    "    for i in driver2.find_elements_by_xpath(\"//a[@class='subTitle ellipsis fleft']\"):\n",
    "        comp_names.append(i.text)\n",
    "#     extracting the jobs href\n",
    "    for i in driver2.find_elements_by_xpath(\"//a[@class='title fw500 ellipsis']\"):\n",
    "        jobs_href.append(i.get_attribute('href'))\n",
    "#     extracting jobs job-description\n",
    "    for i in jobs_href[:12]:\n",
    "        driver2.get(i)\n",
    "        time.sleep(6)\n",
    "        try:\n",
    "            desc=driver2.find_element_by_xpath(\"//section[@class='job-desc']/div[1]\")\n",
    "            jobs_desc.append(desc.text.replace('\\n',''))\n",
    "        except:\n",
    "            desc=driver2.find_element_by_xpath(\"//div[@class='clearboth description']\")\n",
    "            jobs_desc.append(desc.text.replace('\\n',''))\n",
    "#         going back to the Main page\n",
    "        driver2.get('https://www.naukri.com/data-scientist-jobs-in-bangalore?k=data%20scientist&l=bangalore')\n",
    "        time.sleep(8)\n",
    "        \n",
    "    Q2_DF=pd.DataFrame({})\n",
    "    Q2_DF['Job Title']=job_titles[:10]\n",
    "    Q2_DF['Job Location']=job_locs[:10]\n",
    "    Q2_DF['Company Name']=comp_names[:10]\n",
    "    Q2_DF['Job Description']=jobs_desc[:10]\n",
    "    \n",
    "    driver2.close()\n",
    "    \n",
    "    return(Q2_DF)\n",
    "\n",
    "\n",
    "# Calling Function    \n",
    "data_scie1('https://www.naukri.com/')  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Q3: In this question you have to scrape data using the filters available on the webpage, You have to use the location and salary filter.You have to scrape data for “Data Scientist” designation for first 10 job results.You have to scrape the job-title, job-location, company_name, experience_required.The location filter to be used is “Delhi/NCR”.The salary filter to be used is “3-6” lakhs.\n",
    "## Webpage https://www.naukri.com/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Job Title</th>\n",
       "      <th>Job Location</th>\n",
       "      <th>Company Name</th>\n",
       "      <th>Experience Required</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>Delhi / NCR</td>\n",
       "      <td>NatWest Group</td>\n",
       "      <td>4-8 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>Gurgaon/Gurugram</td>\n",
       "      <td>itForte Staffing Services Private Ltd.</td>\n",
       "      <td>3-8 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>Gurgaon/Gurugram</td>\n",
       "      <td>Msg.ai</td>\n",
       "      <td>3-5 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>Gurgaon/Gurugram</td>\n",
       "      <td>NatWest Group</td>\n",
       "      <td>4-8 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>Delhi / NCR</td>\n",
       "      <td>NatWest Group</td>\n",
       "      <td>4-8 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Data Scientist | Python | Machine Learning | D...</td>\n",
       "      <td>Noida(Sector-59 Noida)</td>\n",
       "      <td>Careerera</td>\n",
       "      <td>3-8 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Data Scientist/Data Analyst - Python/Machine L...</td>\n",
       "      <td>Mumbai, Ghaziabad</td>\n",
       "      <td>Change leaders</td>\n",
       "      <td>5-10 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>GCP Presales AIML Architect &amp; Data Scientist (...</td>\n",
       "      <td>Noida</td>\n",
       "      <td>Lecan Solutions Pvt Ltd</td>\n",
       "      <td>6-11 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>GCP Presales AIML Architect &amp; Data Scientist (...</td>\n",
       "      <td>Noida</td>\n",
       "      <td>Lecan Solutions Pvt Ltd</td>\n",
       "      <td>6-11 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Data Scientist Machine Learning</td>\n",
       "      <td>Gurgaon/Gurugram</td>\n",
       "      <td>Delhivery</td>\n",
       "      <td>1-3 Yrs</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                           Job Title            Job Location  \\\n",
       "0                                     Data Scientist             Delhi / NCR   \n",
       "1                                     Data Scientist        Gurgaon/Gurugram   \n",
       "2                                     Data Scientist        Gurgaon/Gurugram   \n",
       "3                                     Data Scientist        Gurgaon/Gurugram   \n",
       "4                                     Data Scientist             Delhi / NCR   \n",
       "5  Data Scientist | Python | Machine Learning | D...  Noida(Sector-59 Noida)   \n",
       "6  Data Scientist/Data Analyst - Python/Machine L...       Mumbai, Ghaziabad   \n",
       "7  GCP Presales AIML Architect & Data Scientist (...                   Noida   \n",
       "8  GCP Presales AIML Architect & Data Scientist (...                   Noida   \n",
       "9                    Data Scientist Machine Learning        Gurgaon/Gurugram   \n",
       "\n",
       "                             Company Name Experience Required  \n",
       "0                           NatWest Group             4-8 Yrs  \n",
       "1  itForte Staffing Services Private Ltd.             3-8 Yrs  \n",
       "2                                  Msg.ai             3-5 Yrs  \n",
       "3                           NatWest Group             4-8 Yrs  \n",
       "4                           NatWest Group             4-8 Yrs  \n",
       "5                               Careerera             3-8 Yrs  \n",
       "6                          Change leaders            5-10 Yrs  \n",
       "7                 Lecan Solutions Pvt Ltd            6-11 Yrs  \n",
       "8                 Lecan Solutions Pvt Ltd            6-11 Yrs  \n",
       "9                               Delhivery             1-3 Yrs  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Function Definition\n",
    "def data_scie2(url):\n",
    "    driver3=webdriver.Chrome(\"C://chromedriver.exe\")\n",
    "    driver3.get(url)\n",
    "    time.sleep(6)\n",
    "    \n",
    "    enter_job=driver3.find_element_by_id('qsb-keyword-sugg')\n",
    "    enter_job.send_keys('Data Scientist')\n",
    "    search_butn=driver3.find_element_by_xpath(\"//div[@class='search-btn']/button\")\n",
    "    search_butn.click()\n",
    "    time.sleep(6)\n",
    "    \n",
    "#     Let's set location filter to Delhi/NCR\n",
    "    filter1=driver3.find_element_by_xpath(\"//label[@class='chkLbl' and @for='chk-Delhi / NCR-cityTypeGid-']/i\")\n",
    "    filter1.click()\n",
    "    time.sleep(6)\n",
    "#   Let's set Salary filter to 3-6 lakhs\n",
    "    filter2=driver3.find_element_by_xpath(\"//label[@class='chkLbl' and @for='chk-3-6 Lakhs-ctcFilter-']/i\")\n",
    "    filter2.click()\n",
    "    time.sleep(6)\n",
    "    \n",
    "#     Let's create empty lists to store necessary information \n",
    "    job_titles=[]\n",
    "    job_locs=[]\n",
    "    comp_names=[]\n",
    "    exp_req=[]\n",
    "    \n",
    "#     extracting job titles\n",
    "    for i in driver3.find_elements_by_xpath(\"//a[@class='title fw500 ellipsis']\"):\n",
    "        job_titles.append(i.text)  \n",
    "#     extracting job locations\n",
    "    for i in driver3.find_elements_by_xpath(\"//li[@class='fleft grey-text br2 placeHolderLi location']/span\"):\n",
    "        job_locs.append(i.text) \n",
    "#     extracting companies names\n",
    "    for i in driver3.find_elements_by_xpath(\"//a[@class='subTitle ellipsis fleft']\"):\n",
    "        comp_names.append(i.text)  \n",
    "#     extracting experience required\n",
    "    for i in driver3.find_elements_by_xpath(\"//li[@class='fleft grey-text br2 placeHolderLi experience']/span\"):\n",
    "        exp_req.append(i.text)\n",
    "            \n",
    "    Q3_DF=pd.DataFrame({})\n",
    "    Q3_DF['Job Title']=job_titles[:10]\n",
    "    Q3_DF['Job Location']=job_locs[:10]\n",
    "    Q3_DF['Company Name']=comp_names[:10]\n",
    "    Q3_DF['Experience Required']=exp_req[:10]\n",
    "    \n",
    "    driver3.close()\n",
    "    \n",
    "    return Q3_DF\n",
    "\n",
    "\n",
    "# Calling Function\n",
    "data_scie2('https://www.naukri.com/')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Q4: Write a python program to scrape data for first 10 job results for Data scientist Designation in Noida location. You have to scrape Company_Name, No. of Days ago when job was posted, Ratings of the Company.\n",
    "## Webpage https://www.glassdoor.co.in/Job/india-jobs-SRCH_IL.0,5_IN115.htm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Company Name</th>\n",
       "      <th>Company Rating</th>\n",
       "      <th>No. of Days ago when job was posted</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Unyscape Infocom Pvt. Ltd</td>\n",
       "      <td>4.1</td>\n",
       "      <td>30d+</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Biz2Credit Inc</td>\n",
       "      <td>3.8</td>\n",
       "      <td>30d+</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Adobe</td>\n",
       "      <td>4.4</td>\n",
       "      <td>6d</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Techlive</td>\n",
       "      <td>5.0</td>\n",
       "      <td>30d+</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Genpact</td>\n",
       "      <td>3.8</td>\n",
       "      <td>2d</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Salasar New Age Technologies</td>\n",
       "      <td>5.0</td>\n",
       "      <td>30d+</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Asquero</td>\n",
       "      <td>3.5</td>\n",
       "      <td>8d</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Salasar New Age Technologies</td>\n",
       "      <td>4.4</td>\n",
       "      <td>30d+</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>CRMNEXT</td>\n",
       "      <td>3.9</td>\n",
       "      <td>13d</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Microsoft</td>\n",
       "      <td>3.0</td>\n",
       "      <td>30d+</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   Company Name  Company Rating  \\\n",
       "0     Unyscape Infocom Pvt. Ltd             4.1   \n",
       "1                Biz2Credit Inc             3.8   \n",
       "2                         Adobe             4.4   \n",
       "3                      Techlive             5.0   \n",
       "4                       Genpact             3.8   \n",
       "5  Salasar New Age Technologies             5.0   \n",
       "6                       Asquero             3.5   \n",
       "7  Salasar New Age Technologies             4.4   \n",
       "8                       CRMNEXT             3.9   \n",
       "9                     Microsoft             3.0   \n",
       "\n",
       "  No. of Days ago when job was posted  \n",
       "0                                30d+  \n",
       "1                                30d+  \n",
       "2                                  6d  \n",
       "3                                30d+  \n",
       "4                                  2d  \n",
       "5                                30d+  \n",
       "6                                  8d  \n",
       "7                                30d+  \n",
       "8                                 13d  \n",
       "9                                30d+  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Function Definition\n",
    "def data_scie3(url):\n",
    "    driver4=webdriver.Chrome('C://chromedriver.exe')\n",
    "    driver4.get(url)\n",
    "    time.sleep(10)\n",
    "    \n",
    "    enter_job=driver4.find_element_by_id('sc.keyword')\n",
    "    enter_job.send_keys('Data Scientist')\n",
    "    enter_loc=driver4.find_element_by_id('sc.location')\n",
    "    enter_loc.clear()\n",
    "    time.sleep(6)\n",
    "    enter_loc.send_keys('Noida')\n",
    "    search_butn=driver4.find_element_by_xpath(\"//button[@id='HeroSearchButton']\")\n",
    "    search_butn.click()\n",
    "    time.sleep(10)\n",
    "    \n",
    "#     Let's create empty lists to store necessary information \n",
    "    comp_names=[]\n",
    "    comp_ratings=[]\n",
    "    days_ago=[]\n",
    "    \n",
    "#     extracting companies names\n",
    "    for i in driver4.find_elements_by_xpath(\"//a[@class=' css-l2wjgv e1n63ojh0 jobLink']/span\"):\n",
    "        comp_names.append(i.text)  \n",
    "#     extracting companies ratings\n",
    "    for i in driver4.find_elements_by_xpath(\"//span[@class='css-19pjha7 e1cjmv6j1']\"):\n",
    "        comp_ratings.append(float(i.text))\n",
    "#     extracting no. of days ago when job was posted\n",
    "    for i in driver4.find_elements_by_xpath(\"//div[@class='d-flex align-items-end pl-std css-mi55ob']\"):\n",
    "        days_ago.append(i.text)\n",
    "            \n",
    "    Q4_DF=pd.DataFrame({})\n",
    "    Q4_DF['Company Name']=comp_names[:10]\n",
    "    Q4_DF['Company Rating']=comp_ratings[:10]\n",
    "    Q4_DF['No. of Days ago when job was posted']=days_ago[:10]\n",
    "    \n",
    "    driver4.close()\n",
    "    \n",
    "    return Q4_DF\n",
    "\n",
    "\n",
    "# Calling Function\n",
    "data_scie3('https://www.glassdoor.co.in/Job/india-jobs-SRCH_IL.0,5_IN115.htm')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Q5: Write a python program to scrape the salary data for Data Scientist designation in Noida location.You have to scrape Company name, Number of salaries, Average salary, Min salary, Max Salary.\n",
    "## Webpage https://www.glassdoor.co.in/Salaries/index.htm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Company Name</th>\n",
       "      <th>Number of Salaries</th>\n",
       "      <th>Average Salary</th>\n",
       "      <th>Min Salary</th>\n",
       "      <th>Max Salary</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Tata Consultancy Services</td>\n",
       "      <td>14 salaries</td>\n",
       "      <td>₹ 6,01,000</td>\n",
       "      <td>₹336L</td>\n",
       "      <td>₹1,080L</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Accenture</td>\n",
       "      <td>14 salaries</td>\n",
       "      <td>₹ 11,51,207</td>\n",
       "      <td>₹579L</td>\n",
       "      <td>₹2,222L</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Delhivery</td>\n",
       "      <td>14 salaries</td>\n",
       "      <td>₹ 12,34,207</td>\n",
       "      <td>₹452L</td>\n",
       "      <td>₹11,669L</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>IBM</td>\n",
       "      <td>13 salaries</td>\n",
       "      <td>₹ 7,63,825</td>\n",
       "      <td>₹589L</td>\n",
       "      <td>₹2,741L</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Ericsson-Worldwide</td>\n",
       "      <td>12 salaries</td>\n",
       "      <td>₹ 7,32,209</td>\n",
       "      <td>₹350L</td>\n",
       "      <td>₹1,619L</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>UnitedHealth Group</td>\n",
       "      <td>10 salaries</td>\n",
       "      <td>₹ 13,88,910</td>\n",
       "      <td>₹1,050L</td>\n",
       "      <td>₹1,500L</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Valiance Solutions</td>\n",
       "      <td>9 salaries</td>\n",
       "      <td>₹ 8,18,515</td>\n",
       "      <td>₹504L</td>\n",
       "      <td>₹1,471L</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Innovaccer</td>\n",
       "      <td>8 salaries</td>\n",
       "      <td>₹ 12,01,403</td>\n",
       "      <td>₹623L</td>\n",
       "      <td>₹1,702L</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>ZS Associates</td>\n",
       "      <td>7 salaries</td>\n",
       "      <td>₹ 10,00,000</td>\n",
       "      <td>₹203L</td>\n",
       "      <td>₹1,817L</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>EXL Service</td>\n",
       "      <td>7 salaries</td>\n",
       "      <td>₹ 11,90,000</td>\n",
       "      <td>₹578L</td>\n",
       "      <td>₹1,500L</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                Company Name Number of Salaries Average Salary Min Salary  \\\n",
       "0  Tata Consultancy Services        14 salaries     ₹ 6,01,000      ₹336L   \n",
       "1                  Accenture        14 salaries    ₹ 11,51,207      ₹579L   \n",
       "2                  Delhivery        14 salaries    ₹ 12,34,207      ₹452L   \n",
       "3                        IBM        13 salaries     ₹ 7,63,825      ₹589L   \n",
       "4         Ericsson-Worldwide        12 salaries     ₹ 7,32,209      ₹350L   \n",
       "5         UnitedHealth Group        10 salaries    ₹ 13,88,910    ₹1,050L   \n",
       "6         Valiance Solutions         9 salaries     ₹ 8,18,515      ₹504L   \n",
       "7                 Innovaccer         8 salaries    ₹ 12,01,403      ₹623L   \n",
       "8              ZS Associates         7 salaries    ₹ 10,00,000      ₹203L   \n",
       "9                EXL Service         7 salaries    ₹ 11,90,000      ₹578L   \n",
       "\n",
       "  Max Salary  \n",
       "0    ₹1,080L  \n",
       "1    ₹2,222L  \n",
       "2   ₹11,669L  \n",
       "3    ₹2,741L  \n",
       "4    ₹1,619L  \n",
       "5    ₹1,500L  \n",
       "6    ₹1,471L  \n",
       "7    ₹1,702L  \n",
       "8    ₹1,817L  \n",
       "9    ₹1,500L  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Function Definition\n",
    "def data_scie4(url):\n",
    "    driver5=webdriver.Chrome('C://chromedriver.exe')\n",
    "    driver5.get(url)\n",
    "    time.sleep(10)\n",
    "    \n",
    "    enter_job=driver5.find_element_by_id('KeywordSearch')\n",
    "    enter_job.send_keys('Data Scientist')\n",
    "    enter_loc=driver5.find_element_by_id('LocationSearch')\n",
    "    enter_loc.clear()\n",
    "    time.sleep(4)\n",
    "    enter_loc.send_keys('Noida')\n",
    "    search_butn=driver5.find_element_by_xpath(\"//button[@id='HeroSearchButton']\")\n",
    "    search_butn.click()\n",
    "    time.sleep(10)\n",
    "    \n",
    "#     Let's create empty lists to store necessary information \n",
    "    comp_names=[]\n",
    "    number_of_salaries=[]\n",
    "    avg_salary=[]\n",
    "    min_salary=[]\n",
    "    max_salary=[]\n",
    "    \n",
    "#     extracting companies names\n",
    "    for i in driver5.find_elements_by_xpath(\"//p[@class='m-0 ']\"):\n",
    "        comp_names.append(i.text)\n",
    "#     extracting Number of salaries\n",
    "    for i in driver5.find_elements_by_xpath(\"//p[@class='css-1uyte9r css-1kuy7z7 m-0 ']\"):\n",
    "        number_of_salaries.append(i.text)   \n",
    "#     extracting Average salary\n",
    "    for i in driver5.find_elements_by_xpath(\"//div[@class='col-2 d-none d-md-flex flex-row justify-content-end']/strong\"):\n",
    "        avg_salary.append(i.text)\n",
    "#     extracting Min salary\n",
    "    for i in driver5.find_elements_by_xpath(\"//div[@class='common__RangeBarStyle__values d-flex justify-content-between ']/span[1]\"):\n",
    "        min_salary.append(i.text)  \n",
    "#     extracting Max salary\n",
    "    for i in driver5.find_elements_by_xpath(\"//div[@class='common__RangeBarStyle__values d-flex justify-content-between ']/span[2]\"):\n",
    "        max_salary.append(i.text)\n",
    "              \n",
    "    Q5_DF=pd.DataFrame({})\n",
    "    Q5_DF['Company Name']=comp_names[:10]\n",
    "    Q5_DF['Number of Salaries']=number_of_salaries[:10]\n",
    "    Q5_DF['Average Salary']=avg_salary[:10]\n",
    "    Q5_DF['Min Salary']=min_salary[:10]\n",
    "    Q5_DF['Max Salary']=max_salary[:10]\n",
    "    \n",
    "    driver5.close()\n",
    "    \n",
    "    return Q5_DF\n",
    "\n",
    "# Calling Function\n",
    "data_scie4('https://www.glassdoor.co.in/Salaries/index.htm')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Q6: Scrape data of first 100 sunglasses listings on flipkart.com. You have to scrape four attributes:Brand, Product Description, Price, Discount %."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Brand</th>\n",
       "      <th>Product Description</th>\n",
       "      <th>Price</th>\n",
       "      <th>Discount %</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ROZZETTA CRAFT</td>\n",
       "      <td>UV Protection, Gradient Round Sunglasses (Free...</td>\n",
       "      <td>₹449</td>\n",
       "      <td>87% off</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ROZZETTA CRAFT</td>\n",
       "      <td>UV Protection, Gradient Round Sunglasses (Free...</td>\n",
       "      <td>₹449</td>\n",
       "      <td>77% off</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Fastrack</td>\n",
       "      <td>UV Protection Wayfarer Sunglasses (Free Size) ...</td>\n",
       "      <td>₹758</td>\n",
       "      <td>15% off</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Fastrack</td>\n",
       "      <td>UV Protection Rectangular Sunglasses (Free Siz...</td>\n",
       "      <td>₹666</td>\n",
       "      <td>16% off</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>PIRASO</td>\n",
       "      <td>UV Protection Aviator Sunglasses (Free Size)  ...</td>\n",
       "      <td>₹314</td>\n",
       "      <td>80% off</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>BKGE</td>\n",
       "      <td>UV Protection, Polarized Rectangular, Retro Sq...</td>\n",
       "      <td>₹315</td>\n",
       "      <td>71% off</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>DEIXELS</td>\n",
       "      <td>UV Protection Rectangular Sunglasses (Free Siz...</td>\n",
       "      <td>₹211</td>\n",
       "      <td>82% off</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>Fastrack</td>\n",
       "      <td>UV Protection Wrap-around Sunglasses (Free Siz...</td>\n",
       "      <td>₹928</td>\n",
       "      <td>15% off</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>Aislin</td>\n",
       "      <td>UV Protection, Gradient Round Sunglasses (58) ...</td>\n",
       "      <td>₹472</td>\n",
       "      <td>69% off</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>Fastrack</td>\n",
       "      <td>UV Protection Wrap-around Sunglasses (Free Siz...</td>\n",
       "      <td>₹759</td>\n",
       "      <td>15% off</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "              Brand                                Product Description Price  \\\n",
       "0   ROZZETTA CRAFT   UV Protection, Gradient Round Sunglasses (Free...  ₹449   \n",
       "1   ROZZETTA CRAFT   UV Protection, Gradient Round Sunglasses (Free...  ₹449   \n",
       "2         Fastrack   UV Protection Wayfarer Sunglasses (Free Size) ...  ₹758   \n",
       "3         Fastrack   UV Protection Rectangular Sunglasses (Free Siz...  ₹666   \n",
       "4           PIRASO   UV Protection Aviator Sunglasses (Free Size)  ...  ₹314   \n",
       "..              ...                                                ...   ...   \n",
       "95            BKGE   UV Protection, Polarized Rectangular, Retro Sq...  ₹315   \n",
       "96         DEIXELS   UV Protection Rectangular Sunglasses (Free Siz...  ₹211   \n",
       "97        Fastrack   UV Protection Wrap-around Sunglasses (Free Siz...  ₹928   \n",
       "98          Aislin   UV Protection, Gradient Round Sunglasses (58) ...  ₹472   \n",
       "99        Fastrack   UV Protection Wrap-around Sunglasses (Free Siz...  ₹759   \n",
       "\n",
       "   Discount %  \n",
       "0     87% off  \n",
       "1     77% off  \n",
       "2     15% off  \n",
       "3     16% off  \n",
       "4     80% off  \n",
       "..        ...  \n",
       "95    71% off  \n",
       "96    82% off  \n",
       "97    15% off  \n",
       "98    69% off  \n",
       "99    15% off  \n",
       "\n",
       "[100 rows x 4 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Function Definition\n",
    "def sunglasses(url):\n",
    "    driver6=webdriver.Chrome(\"c://chromedriver.exe\")\n",
    "    driver6.get(url)\n",
    "    time.sleep(10)\n",
    "    \n",
    "    close=driver6.find_element_by_xpath(\"//button[@class='_2KpZ6l _2doB4z']\")\n",
    "    close.click()\n",
    "    \n",
    "    enter_sunglasses=driver6.find_element_by_xpath(\"//input[@title='Search for products, brands and more']\")\n",
    "    enter_sunglasses.send_keys('sunglasses')\n",
    "    search_butn=driver6.find_element_by_xpath(\"//button[@class='L0Z3Pu' and @type='submit']\")\n",
    "    search_butn.click()\n",
    "    time.sleep(10)\n",
    "    \n",
    "#     extracting all sunglasses href from page-1 to page-3\n",
    "    sg_href=[]\n",
    "    for page in range(0,3):\n",
    "        for i in driver6.find_elements_by_xpath(\"//a[@class='_2UzuFa']\"):\n",
    "            sg_href.append(i.get_attribute('href'))\n",
    "#         to enter next page\n",
    "        try:\n",
    "            nxt_page=driver6.find_element_by_xpath(\"//nav[@class='yFHi8N']/a[12]\")\n",
    "            nxt_page.click()\n",
    "        except:\n",
    "            nxt_page=driver6.find_element_by_xpath(\"//nav[@class='yFHi8N']/a[11]\")\n",
    "            nxt_page.click()\n",
    "        time.sleep(8)\n",
    "    \n",
    "# Let's create empty lists to store necessary information\n",
    "    brand=[]\n",
    "    desc=[]\n",
    "    price=[]\n",
    "    discount=[]\n",
    "\n",
    "    for urls in sg_href[:108]:\n",
    "        driver6.get(urls)\n",
    "        delay=10\n",
    "        WebDriverWait(driver6, delay).until(EC.presence_of_element_located((By.CLASS_NAME, 'G6XhRU')))\n",
    "    \n",
    "#     extracting Brand\n",
    "        b=driver6.find_element_by_xpath(\"//span[@class='G6XhRU']\")\n",
    "        brand.append(b.text)\n",
    "#     extracting Product Description\n",
    "        try:\n",
    "            d=driver6.find_element_by_xpath(\"//h1[@class='yhB1nd']/span[2]\")\n",
    "            desc.append(d.text)\n",
    "        except:\n",
    "            desc.append(np.nan)\n",
    "#     extracting Price\n",
    "        try:\n",
    "            p=driver6.find_element_by_xpath(\"//div[@class='_30jeq3 _16Jk6d']\")\n",
    "            price.append(p.text)\n",
    "        except:\n",
    "            price.append(np.nan)\n",
    "#     extracting Discount%\n",
    "        try:\n",
    "            dis=driver6.find_element_by_xpath(\"//div[@class='_3Ay6Sb _31Dcoz pZkvcx']/span\")\n",
    "            discount.append(dis.text)\n",
    "        except:\n",
    "            discount.append(np.nan)\n",
    "    \n",
    "    Q6_DF=pd.DataFrame({})\n",
    "    Q6_DF['Brand']=brand[:100]\n",
    "    Q6_DF['Product Description']=desc[:100]\n",
    "    Q6_DF['Price']=price[:100]\n",
    "    Q6_DF['Discount %']=discount[:100]\n",
    "    \n",
    "    driver6.close()\n",
    "    \n",
    "    return Q6_DF\n",
    "\n",
    "\n",
    "# Calling Function\n",
    "sunglasses('https://www.flipkart.com/')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Q7: Scrape 100 reviews data from flipkart.com for iphone11 phone. You have to go the link: 'https://www.flipkart.com/apple-iphone-11-black-64-gb-includes-earpods-power-adapter/product-reviews/itm0f37c2240b217?pid=MOBFKCTSVZAXUHGR&lid=LSTMOBFKCTSVZAXUHGREPBFGI&marketplace=FLIPKART'. You have to scrape attributes such as Rating, Review_summary, Full review."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Ratings</th>\n",
       "      <th>Review Summary</th>\n",
       "      <th>Full Review</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5.0</td>\n",
       "      <td>Brilliant</td>\n",
       "      <td>The Best Phone for the MoneyThe iPhone 11 offe...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5.0</td>\n",
       "      <td>Perfect product!</td>\n",
       "      <td>Amazing phone with great cameras and better ba...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5.0</td>\n",
       "      <td>Worth every penny</td>\n",
       "      <td>Previously I was using one plus 3t it was a gr...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5.0</td>\n",
       "      <td>Great product</td>\n",
       "      <td>Amazing Powerful and Durable Gadget.I’m am ver...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5.0</td>\n",
       "      <td>Highly recommended</td>\n",
       "      <td>iphone 11 is a very good phone to buy only if ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>5.0</td>\n",
       "      <td>Must buy!</td>\n",
       "      <td>I will just say its an awesome phone. Starting...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>5.0</td>\n",
       "      <td>Worth every penny</td>\n",
       "      <td>Just go for it without a second thought, if yo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>5.0</td>\n",
       "      <td>Fabulous!</td>\n",
       "      <td>I really liked the budget iPhone. First I thou...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>5.0</td>\n",
       "      <td>Wonderful</td>\n",
       "      <td>Dont think too much guys. perfect phone for da...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>5.0</td>\n",
       "      <td>Classy product</td>\n",
       "      <td>Amazing delivery. Got my phone a day before ex...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    Ratings      Review Summary  \\\n",
       "0       5.0           Brilliant   \n",
       "1       5.0    Perfect product!   \n",
       "2       5.0   Worth every penny   \n",
       "3       5.0       Great product   \n",
       "4       5.0  Highly recommended   \n",
       "..      ...                 ...   \n",
       "95      5.0           Must buy!   \n",
       "96      5.0   Worth every penny   \n",
       "97      5.0           Fabulous!   \n",
       "98      5.0           Wonderful   \n",
       "99      5.0      Classy product   \n",
       "\n",
       "                                          Full Review  \n",
       "0   The Best Phone for the MoneyThe iPhone 11 offe...  \n",
       "1   Amazing phone with great cameras and better ba...  \n",
       "2   Previously I was using one plus 3t it was a gr...  \n",
       "3   Amazing Powerful and Durable Gadget.I’m am ver...  \n",
       "4   iphone 11 is a very good phone to buy only if ...  \n",
       "..                                                ...  \n",
       "95  I will just say its an awesome phone. Starting...  \n",
       "96  Just go for it without a second thought, if yo...  \n",
       "97  I really liked the budget iPhone. First I thou...  \n",
       "98  Dont think too much guys. perfect phone for da...  \n",
       "99  Amazing delivery. Got my phone a day before ex...  \n",
       "\n",
       "[100 rows x 3 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Function Definition\n",
    "def iphone(url):\n",
    "    driver7=webdriver.Chrome('C://chromedriver.exe')\n",
    "    driver7.get(url)\n",
    "    time.sleep(8)\n",
    "    \n",
    "#     Let's create empty lists to store necessary information\n",
    "    ratings=[]\n",
    "    review_summary=[]\n",
    "    full_review=[]\n",
    "    \n",
    "    for page in range(0,14):\n",
    "#         extracting Ratings\n",
    "        for i in driver7.find_elements_by_xpath(\"//div[@class='_3LWZlK _1BLPMq']\"):\n",
    "            ratings.append(float(i.text))\n",
    "#         extracting Review Summary\n",
    "        for i in driver7.find_elements_by_xpath(\"//p[@class='_2-N8zT']\"):\n",
    "            review_summary.append(i.text)\n",
    "#         clicking 'Read More', so that we can extract full review\n",
    "        for i in driver7.find_elements_by_xpath(\"//span[@class='_1BWGvX']/span\"):\n",
    "            i.click\n",
    "#         extracting Full Review\n",
    "        for i in driver7.find_elements_by_xpath(\"//div[@class='t-ZTKy']/div/div\"):\n",
    "            full_review.append(i.text.replace('\\n',''))\n",
    "#         to enter next page \n",
    "        try:\n",
    "            nxt_page=driver7.find_element_by_xpath(\"//nav[@class='yFHi8N']/a[12]\")\n",
    "            nxt_page.click()\n",
    "        except:\n",
    "            nxt_page=driver7.find_element_by_xpath(\"//nav[@class='yFHi8N']/a[11]\")\n",
    "            nxt_page.click()   \n",
    "        time.sleep(8)\n",
    "        \n",
    "    Q7_DF=pd.DataFrame({})\n",
    "    Q7_DF['Ratings']=ratings[:100]\n",
    "    Q7_DF['Review Summary']=review_summary[:100]\n",
    "    Q7_DF['Full Review']=full_review[:100]\n",
    "    \n",
    "    driver7.close()\n",
    "    \n",
    "    return Q7_DF\n",
    "\n",
    "\n",
    "# Calling Function\n",
    "iphone('https://www.flipkart.com/apple-iphone-11-black-64-gb-includes-earpods-power-adapter/product-reviews/itm0f37c2240b217?pid=MOBFKCTSVZAXUHGR&lid=LSTMOBFKCTSVZAXUHGREPBFGI&marketplace=FLIPKART')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Q8: Scrape data for first 100 sneakers you find when you visit flipkart.com and search for “sneakers” in the search field. You have to scrape 4 attributes of each sneaker: Brand, Product Description, Price, Discount %."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Brand</th>\n",
       "      <th>Product Description</th>\n",
       "      <th>Price</th>\n",
       "      <th>Discount %</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>French Connection</td>\n",
       "      <td>Sneakers For Men  (Navy)</td>\n",
       "      <td>₹799</td>\n",
       "      <td>60% off</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Extoes</td>\n",
       "      <td>Modern Trendy Shoes Combo pack of 4 Sneakers F...</td>\n",
       "      <td>₹798</td>\n",
       "      <td>46% off</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Chevit</td>\n",
       "      <td>Perfect &amp; Affordable Combo Pack of 02 Pairs Sn...</td>\n",
       "      <td>₹499</td>\n",
       "      <td>72% off</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Robbie jones</td>\n",
       "      <td>Casual Sneakers Shoes For Men Sneakers For Men...</td>\n",
       "      <td>₹399</td>\n",
       "      <td>60% off</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Chevit</td>\n",
       "      <td>Combo Pack of 4 Casual Sneakers With Sneakers ...</td>\n",
       "      <td>₹474</td>\n",
       "      <td>76% off</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>SHOEFLY</td>\n",
       "      <td>Combo Men Pack of 2 Loafers Shoes Sneakers For...</td>\n",
       "      <td>₹299</td>\n",
       "      <td>70% off</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>zovim</td>\n",
       "      <td>casual , Partywear Sneakers Shoes For Men's an...</td>\n",
       "      <td>₹439</td>\n",
       "      <td>56% off</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>Englewood</td>\n",
       "      <td>White Shoes For Men | Casual White Laceups Sho...</td>\n",
       "      <td>₹496</td>\n",
       "      <td>66% off</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>Kraasa</td>\n",
       "      <td>Casuals, Canvas, Partywear Sneakers For Men  (...</td>\n",
       "      <td>₹499</td>\n",
       "      <td>50% off</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>ROCKFIELD</td>\n",
       "      <td>Sneakers For Men  (Grey)</td>\n",
       "      <td>₹450</td>\n",
       "      <td>54% off</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                 Brand                                Product Description  \\\n",
       "0   French Connection                            Sneakers For Men  (Navy)   \n",
       "1              Extoes   Modern Trendy Shoes Combo pack of 4 Sneakers F...   \n",
       "2              Chevit   Perfect & Affordable Combo Pack of 02 Pairs Sn...   \n",
       "3        Robbie jones   Casual Sneakers Shoes For Men Sneakers For Men...   \n",
       "4              Chevit   Combo Pack of 4 Casual Sneakers With Sneakers ...   \n",
       "..                 ...                                                ...   \n",
       "95            SHOEFLY   Combo Men Pack of 2 Loafers Shoes Sneakers For...   \n",
       "96              zovim   casual , Partywear Sneakers Shoes For Men's an...   \n",
       "97          Englewood   White Shoes For Men | Casual White Laceups Sho...   \n",
       "98             Kraasa   Casuals, Canvas, Partywear Sneakers For Men  (...   \n",
       "99          ROCKFIELD                            Sneakers For Men  (Grey)   \n",
       "\n",
       "   Price Discount %  \n",
       "0   ₹799    60% off  \n",
       "1   ₹798    46% off  \n",
       "2   ₹499    72% off  \n",
       "3   ₹399    60% off  \n",
       "4   ₹474    76% off  \n",
       "..   ...        ...  \n",
       "95  ₹299    70% off  \n",
       "96  ₹439    56% off  \n",
       "97  ₹496    66% off  \n",
       "98  ₹499    50% off  \n",
       "99  ₹450    54% off  \n",
       "\n",
       "[100 rows x 4 columns]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Function Definition\n",
    "def sneakers(url):\n",
    "    driver8=webdriver.Chrome(\"c://chromedriver.exe\")\n",
    "    driver8.get(url)\n",
    "    time.sleep(8)\n",
    "    \n",
    "    close=driver8.find_element_by_xpath(\"//button[@class='_2KpZ6l _2doB4z']\")\n",
    "    close.click()\n",
    "    \n",
    "    enter_sneakers=driver8.find_element_by_xpath(\"//input[@title='Search for products, brands and more']\")\n",
    "    enter_sneakers.send_keys('sneakers')\n",
    "    search_butn=driver8.find_element_by_xpath(\"//button[@class='L0Z3Pu' and @type='submit']\")\n",
    "    search_butn.click()\n",
    "    time.sleep(8)\n",
    "    \n",
    "#     extracting all sneakers href from page-1 to page-3\n",
    "    sn_href=[]\n",
    "    for page in range(0,3):\n",
    "        for i in driver8.find_elements_by_xpath(\"//a[@class='_2UzuFa']\"):\n",
    "            sn_href.append(i.get_attribute('href'))\n",
    "#         to enter next page\n",
    "        try:\n",
    "            nxt_page=driver8.find_element_by_xpath(\"//nav[@class='yFHi8N']/a[12]\")\n",
    "            nxt_page.click()\n",
    "        except:\n",
    "            nxt_page=driver8.find_element_by_xpath(\"//nav[@class='yFHi8N']/a[11]\")\n",
    "            nxt_page.click()\n",
    "        time.sleep(8)\n",
    "#     Let's create empty lists to store necessary information    \n",
    "    brand=[]\n",
    "    desc=[]\n",
    "    price=[]\n",
    "    discount=[]\n",
    "\n",
    "    for urls in sn_href[:108]:\n",
    "        driver8.get(urls)\n",
    "        delay=20\n",
    "        WebDriverWait(driver8, delay).until(EC.presence_of_element_located((By.CLASS_NAME, 'G6XhRU')))\n",
    "        \n",
    "#         extracting Brand\n",
    "        b=driver8.find_element_by_xpath(\"//span[@class='G6XhRU']\")\n",
    "        brand.append(b.text)\n",
    "#         extracting Product Description\n",
    "        try:\n",
    "            d=driver8.find_element_by_xpath(\"//h1[@class='yhB1nd']/span[2]\")\n",
    "            desc.append(d.text)\n",
    "        except:\n",
    "            desc.append(np.nan)\n",
    "#         extracting Price\n",
    "        try:\n",
    "            p=driver8.find_element_by_xpath(\"//div[@class='_30jeq3 _16Jk6d']\")\n",
    "            price.append(p.text)\n",
    "        except:\n",
    "            price.append(np.nan)\n",
    "#         extracting Discount%\n",
    "        try:\n",
    "            dis=driver8.find_element_by_xpath(\"//div[@class='_3Ay6Sb _31Dcoz pZkvcx']/span\")\n",
    "            discount.append(dis.text)\n",
    "        except:\n",
    "            discount.append(np.nan)\n",
    "    \n",
    "    Q8_DF=pd.DataFrame({})\n",
    "    Q8_DF['Brand']=brand[:100]\n",
    "    Q8_DF['Product Description']=desc[:100]\n",
    "    Q8_DF['Price']=price[:100]\n",
    "    Q8_DF['Discount %']=discount[:100]\n",
    "    \n",
    "    driver8.close()\n",
    "    \n",
    "    return Q8_DF\n",
    "\n",
    "# Calling Function\n",
    "sneakers('https://www.flipkart.com/')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Q9: Go to the link - https://www.myntra.com/shoes. Set Price filter to “Rs. 6649 to Rs. 13099” , Color filter to “Black”. And then scrape first 100 shoes data you get. The data should include “Brand” of the shoes , short Shoe description, Price of the shoes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Brand</th>\n",
       "      <th>Product Description</th>\n",
       "      <th>Price</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ADIDAS Originals</td>\n",
       "      <td>Men Black Woven Design Nite Jogger Sneakers</td>\n",
       "      <td>Rs. 11199</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Nike</td>\n",
       "      <td>Men Black REACT MILER Running Shoes</td>\n",
       "      <td>Rs. 9345</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Nike</td>\n",
       "      <td>Men Black AIR ZOOM VOMERO 15 Running Shoes</td>\n",
       "      <td>Rs. 11470</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Nike</td>\n",
       "      <td>Women Black REACT PHANTOM RUN FK 2 Running Shoes</td>\n",
       "      <td>Rs. 9596</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Nike</td>\n",
       "      <td>Unisex Black PHANTOM GT ACADEMY FG/MG Football...</td>\n",
       "      <td>Rs. 7195</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>Tommy Hilfiger</td>\n",
       "      <td>Men Black Solid Sneakers</td>\n",
       "      <td>Rs. 6749</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>Ruosh</td>\n",
       "      <td>Men Black Leather Semiformal Slip-Ons</td>\n",
       "      <td>Rs. 6990</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>Ruosh</td>\n",
       "      <td>Men Black Solid Leather Formal Monks</td>\n",
       "      <td>Rs. 6990</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>Hush Puppies</td>\n",
       "      <td>Men Black Leather Derbys</td>\n",
       "      <td>Rs. 7999</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>Ruosh</td>\n",
       "      <td>Work Men Black Rare Leather Textured Derbys</td>\n",
       "      <td>Rs. 8990</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "               Brand                                Product Description  \\\n",
       "0   ADIDAS Originals        Men Black Woven Design Nite Jogger Sneakers   \n",
       "1               Nike                Men Black REACT MILER Running Shoes   \n",
       "2               Nike         Men Black AIR ZOOM VOMERO 15 Running Shoes   \n",
       "3               Nike   Women Black REACT PHANTOM RUN FK 2 Running Shoes   \n",
       "4               Nike  Unisex Black PHANTOM GT ACADEMY FG/MG Football...   \n",
       "..               ...                                                ...   \n",
       "95    Tommy Hilfiger                           Men Black Solid Sneakers   \n",
       "96             Ruosh              Men Black Leather Semiformal Slip-Ons   \n",
       "97             Ruosh               Men Black Solid Leather Formal Monks   \n",
       "98      Hush Puppies                           Men Black Leather Derbys   \n",
       "99             Ruosh        Work Men Black Rare Leather Textured Derbys   \n",
       "\n",
       "        Price  \n",
       "0   Rs. 11199  \n",
       "1    Rs. 9345  \n",
       "2   Rs. 11470  \n",
       "3    Rs. 9596  \n",
       "4    Rs. 7195  \n",
       "..        ...  \n",
       "95   Rs. 6749  \n",
       "96   Rs. 6990  \n",
       "97   Rs. 6990  \n",
       "98   Rs. 7999  \n",
       "99   Rs. 8990  \n",
       "\n",
       "[100 rows x 3 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def shoes(url):\n",
    "    driver9=webdriver.Chrome(\"C://chromedriver.exe\")\n",
    "    driver9.get(url)\n",
    "    time.sleep(8)\n",
    "    \n",
    "#     setting color to \"Black\"\n",
    "    filter2=driver9.find_elements_by_xpath(\"//li[@class='colour-listItem']/label/div\")\n",
    "    filter2[0].click()\n",
    "    time.sleep(6)\n",
    "#     setting price to “Rs. 6649 to Rs. 13099” \n",
    "    filter1=driver9.find_elements_by_xpath(\"//ul[@class='price-list']/li/label/div\")\n",
    "    filter1[1].click()\n",
    "    time.sleep(6)\n",
    "    \n",
    "#     extracting all shoes href from page-1 to page-3\n",
    "    shoes_href=[]\n",
    "    for page in range(0,3):\n",
    "        for i in driver9.find_elements_by_xpath(\"//a[@style='display: block;']\"):\n",
    "                shoes_href.append(i.get_attribute('href'))\n",
    "#         to enter next page\n",
    "        nxt_page=driver9.find_element_by_xpath(\"//li[@class='pagination-next']/a\").get_attribute('href')\n",
    "        driver9.get(nxt_page)\n",
    "        time.sleep(8)\n",
    "        \n",
    "#     Let's create empty lists to store necessary information    \n",
    "    brand=[]\n",
    "    desc=[]\n",
    "    price=[]\n",
    "    \n",
    "    for urls in shoes_href[:108]:\n",
    "        driver9.get(urls)\n",
    "        delay=10\n",
    "        WebDriverWait(driver9, delay).until(EC.presence_of_element_located((By.CLASS_NAME, 'pdp-title')))\n",
    "        \n",
    "#         extracting Brand\n",
    "        b=driver9.find_element_by_xpath(\"//h1[@class='pdp-title']\")\n",
    "        brand.append(b.text)\n",
    "#         extracting Product Description\n",
    "        try:\n",
    "            d=driver9.find_element_by_xpath(\"//h1[@class='pdp-name']\")\n",
    "            desc.append(d.text)\n",
    "        except:\n",
    "            desc.append(np.nan)\n",
    "#         extracting Price\n",
    "        try:\n",
    "            p=driver9.find_element_by_xpath(\"//span[@class='pdp-price']/strong\")\n",
    "            price.append(p.text)\n",
    "        except:\n",
    "            price.append(np.nan)\n",
    "        \n",
    "    Q9_DF=pd.DataFrame({})\n",
    "    Q9_DF['Brand']=brand[:100]\n",
    "    Q9_DF['Product Description']=desc[:100]\n",
    "    Q9_DF['Price']=price[:100]\n",
    "    \n",
    "    driver9.close()\n",
    "    \n",
    "    return Q9_DF\n",
    "\n",
    "\n",
    "shoes('https://www.myntra.com/shoes')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Q10: Go to the webpage https://www.amazon.in/. Enter “Laptop” in the search field and then click the search icon.Then set CPU Type filter to “Intel Core i7” and “Intel Core i9”.After setting the filters scrape first 10 laptops data. You have to scrape 3 attributes for each laptop:Title, Ratings, Price."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "driver10=webdriver.Chrome('C://chromedriver.exe')\n",
    "driver10.get('https://www.amazon.in/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "enter_laptop=driver10.find_element_by_id('twotabsearchtextbox')\n",
    "enter_laptop.send_keys('Laptop')\n",
    "search_butn=driver10.find_element_by_id(\"nav-search-submit-button\")\n",
    "search_butn.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Main Page\n",
    "\n",
    "driver10.get('https://www.amazon.in/s?k=Laptop&ref=nb_sb_noss')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# extracting elements to set CPU Type filter to “Intel Core i7” and “Intel Core i9”\n",
    "filter1=driver10.find_elements_by_xpath(\"//ul[@aria-labelledby='p_n_feature_thirteen_browse-bin-title']/li/span/a/div/label/i\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "    Since webpage is not allowing to set both CPU Types at once, so let's first set CPU Type to “Intel Core i7”."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# setting CPU Type filter to “Intel Core i7”\n",
    "filter1[-3].click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# extracting mobiles href \n",
    "\n",
    "mobiles_href=[]\n",
    "for i in driver10.find_elements_by_xpath(\"//a[@class='a-link-normal a-text-normal']\"):\n",
    "    mobiles_href.append(i.get_attribute('href'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's create empty lists to store necessary information\n",
    "title=[]\n",
    "price=[]\n",
    "ratings=[]\n",
    "\n",
    "for url in mobiles_href[:10]:\n",
    "    driver10.get(url)\n",
    "    time.sleep(6)\n",
    "    \n",
    "#     extracting title\n",
    "    t=driver10.find_element_by_xpath(\"//span[@id='productTitle']\")\n",
    "    title.append(t.text)\n",
    "#     extracting price\n",
    "    try:\n",
    "        p=driver10.find_element_by_xpath(\"//span[@id='priceblock_ourprice']\")\n",
    "        price.append(float(p.text[2:].replace(',','')))\n",
    "    except:\n",
    "        price.append(np.nan)\n",
    "#     extracting ratings\n",
    "    try:\n",
    "        r=driver10.find_element_by_xpath(\"//span[@id='acrPopover']\")\n",
    "        ratings.append(r.get_attribute('title'))\n",
    "    except:\n",
    "        ratings.append(np.nan)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# going back to the Main Page\n",
    "\n",
    "driver10.get('https://www.amazon.in/s?k=Laptop&ref=nb_sb_noss')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# extracting elements to set CPU Type filter to “Intel Core i9”\n",
    "\n",
    "filter2=driver10.find_elements_by_xpath(\"//ul[@aria-labelledby='p_n_feature_thirteen_browse-bin-title']/li/span/a/div/label/i\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# setting CPU Type filter to “Intel Core i9”\n",
    "\n",
    "filter2[-2].click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# extracting mobiles href \n",
    "\n",
    "mobiles_href=[]\n",
    "for i in driver10.find_elements_by_xpath(\"//a[@class='a-link-normal a-text-normal']\"):\n",
    "    mobiles_href.append(i.get_attribute('href'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "for url in mobiles_href[:10]:\n",
    "    driver10.get(url)\n",
    "    time.sleep(6)\n",
    "    \n",
    "#     extracting title\n",
    "    t=driver10.find_element_by_xpath(\"//span[@id='productTitle']\")\n",
    "    title.append(t.text)\n",
    "#     extracting price\n",
    "    try:\n",
    "        p=driver10.find_element_by_xpath(\"//span[@id='priceblock_ourprice']\")\n",
    "        price.append(float(p.text[2:].replace(',','')))\n",
    "    except:\n",
    "        price.append(np.nan)\n",
    "#     extracting ratings\n",
    "    try:\n",
    "        r=driver10.find_element_by_xpath(\"//span[@id='acrPopover']\")\n",
    "        ratings.append(r.get_attribute('title'))\n",
    "    except:\n",
    "        ratings.append(np.nan)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "Q10_DF=pd.DataFrame({})\n",
    "Q10_DF['Title']=title\n",
    "Q10_DF['Price']=price\n",
    "Q10_DF['Rating']=ratings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Title</th>\n",
       "      <th>Price</th>\n",
       "      <th>Rating</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Mi Notebook Horizon Edition 14 Intel Core i7-1...</td>\n",
       "      <td>59999.0</td>\n",
       "      <td>4.3 out of 5 stars</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Lenovo Yoga 9 11th Gen Intel Core i7 14-inch 4...</td>\n",
       "      <td>167990.0</td>\n",
       "      <td>5.0 out of 5 stars</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>(Renewed) Lenovo Thinkpad Yoga S1 Laptop (CORE...</td>\n",
       "      <td>38990.0</td>\n",
       "      <td>1.0 out of 5 stars</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>HP 14 Thin &amp; Light 14-inch FHD Laptop (11th Ge...</td>\n",
       "      <td>76500.0</td>\n",
       "      <td>4.6 out of 5 stars</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Lenovo Legion 5Pi 10th Gen Intel Core i7 15.6\"...</td>\n",
       "      <td>135490.0</td>\n",
       "      <td>4.3 out of 5 stars</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Mi Notebook Horizon Edition 14 Intel Core i5-1...</td>\n",
       "      <td>54999.0</td>\n",
       "      <td>4.3 out of 5 stars</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>LifeDigital ZED AIR CX7 15.6 IPS FHD Screen Bl...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.5 out of 5 stars</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>HP Pavilion Gaming 11th Gen Intel Core i7 Proc...</td>\n",
       "      <td>83077.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Lenovo Legion Y540 Intel Core i7 9th Gen 15.6 ...</td>\n",
       "      <td>78990.0</td>\n",
       "      <td>4.1 out of 5 stars</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>LifeDigital ZED AIR CX7 15.6 IPS FHD Screen Bl...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.0 out of 5 stars</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>ASUS ZenBook Pro Duo Intel Core i9-10980HK 10t...</td>\n",
       "      <td>259990.0</td>\n",
       "      <td>3.3 out of 5 stars</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>ASUS ROG G703GI-E5148T 17.3-inch FHD 144Hz/3ms...</td>\n",
       "      <td>522077.0</td>\n",
       "      <td>3.9 out of 5 stars</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>Dell XPS 9570 15.6-inch UHD Laptop (8th Gen i9...</td>\n",
       "      <td>227200.0</td>\n",
       "      <td>2.3 out of 5 stars</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>Dell Alienware m15(R3) 15.6-inch UHD Gaming La...</td>\n",
       "      <td>342990.0</td>\n",
       "      <td>3.0 out of 5 stars</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>ASUS ZenBook Pro Duo UX581GV-H2041T Intel Core...</td>\n",
       "      <td>274990.0</td>\n",
       "      <td>4.0 out of 5 stars</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>Dell Alienware 17 Area 51 9thGeneration Corei9...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4.2 out of 5 stars</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>ASUS ROG Strix Scar 15 (2020), 15.6\" FHD 300Hz...</td>\n",
       "      <td>214990.0</td>\n",
       "      <td>1.0 out of 5 stars</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>HP Omen X 2S Core i9 9th Gen 15.6-inch Dual Sc...</td>\n",
       "      <td>364800.0</td>\n",
       "      <td>4.4 out of 5 stars</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>Dell G7 7500 15.6inch FHD 300 Hz Display Gamin...</td>\n",
       "      <td>206990.0</td>\n",
       "      <td>5.0 out of 5 stars</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>Lenovo Legion 7 10th Gen Intel Core i9 15.6 in...</td>\n",
       "      <td>259990.0</td>\n",
       "      <td>3.1 out of 5 stars</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                Title     Price  \\\n",
       "0   Mi Notebook Horizon Edition 14 Intel Core i7-1...   59999.0   \n",
       "1   Lenovo Yoga 9 11th Gen Intel Core i7 14-inch 4...  167990.0   \n",
       "2   (Renewed) Lenovo Thinkpad Yoga S1 Laptop (CORE...   38990.0   \n",
       "3   HP 14 Thin & Light 14-inch FHD Laptop (11th Ge...   76500.0   \n",
       "4   Lenovo Legion 5Pi 10th Gen Intel Core i7 15.6\"...  135490.0   \n",
       "5   Mi Notebook Horizon Edition 14 Intel Core i5-1...   54999.0   \n",
       "6   LifeDigital ZED AIR CX7 15.6 IPS FHD Screen Bl...       NaN   \n",
       "7   HP Pavilion Gaming 11th Gen Intel Core i7 Proc...   83077.0   \n",
       "8   Lenovo Legion Y540 Intel Core i7 9th Gen 15.6 ...   78990.0   \n",
       "9   LifeDigital ZED AIR CX7 15.6 IPS FHD Screen Bl...       NaN   \n",
       "10  ASUS ZenBook Pro Duo Intel Core i9-10980HK 10t...  259990.0   \n",
       "11  ASUS ROG G703GI-E5148T 17.3-inch FHD 144Hz/3ms...  522077.0   \n",
       "12  Dell XPS 9570 15.6-inch UHD Laptop (8th Gen i9...  227200.0   \n",
       "13  Dell Alienware m15(R3) 15.6-inch UHD Gaming La...  342990.0   \n",
       "14  ASUS ZenBook Pro Duo UX581GV-H2041T Intel Core...  274990.0   \n",
       "15  Dell Alienware 17 Area 51 9thGeneration Corei9...       NaN   \n",
       "16  ASUS ROG Strix Scar 15 (2020), 15.6\" FHD 300Hz...  214990.0   \n",
       "17  HP Omen X 2S Core i9 9th Gen 15.6-inch Dual Sc...  364800.0   \n",
       "18  Dell G7 7500 15.6inch FHD 300 Hz Display Gamin...  206990.0   \n",
       "19  Lenovo Legion 7 10th Gen Intel Core i9 15.6 in...  259990.0   \n",
       "\n",
       "                Rating  \n",
       "0   4.3 out of 5 stars  \n",
       "1   5.0 out of 5 stars  \n",
       "2   1.0 out of 5 stars  \n",
       "3   4.6 out of 5 stars  \n",
       "4   4.3 out of 5 stars  \n",
       "5   4.3 out of 5 stars  \n",
       "6   3.5 out of 5 stars  \n",
       "7                  NaN  \n",
       "8   4.1 out of 5 stars  \n",
       "9   2.0 out of 5 stars  \n",
       "10  3.3 out of 5 stars  \n",
       "11  3.9 out of 5 stars  \n",
       "12  2.3 out of 5 stars  \n",
       "13  3.0 out of 5 stars  \n",
       "14  4.0 out of 5 stars  \n",
       "15  4.2 out of 5 stars  \n",
       "16  1.0 out of 5 stars  \n",
       "17  4.4 out of 5 stars  \n",
       "18  5.0 out of 5 stars  \n",
       "19  3.1 out of 5 stars  "
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Q10_DF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "driver10.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
